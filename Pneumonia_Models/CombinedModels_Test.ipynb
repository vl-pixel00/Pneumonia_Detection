{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Device: mps\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "This script was written as a test for the combined pnemunoina models to observe how well it can do on an unseen set of data. \n",
    "Since there aren't many other reliable pneumonia datasets available online, I chose to use a COVID-19 dataset that I found on Kaggle.\n",
    "Even if there are generally quite a few differences between the two diseases in terms of how they appear in X-ray imagery, the symptoms are very similar. \n",
    "Hence why I wanted to see how well the model could perform on a different dataset without actual training.\n",
    "\n",
    "Reference:\n",
    "Khoong, W.H. (2020) COVID-19 X-ray Dataset: Train-Test Sets. Available at: https://www.kaggle.com/datasets/khoongweihao/covid19-xray-dataset-train-test-sets (Accessed: 9 January 2025).\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pathlib\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import Utils.TorchUtils as Utils\n",
    "\n",
    "device = Utils.get_device()\n",
    "print(f\"Found Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset location: covid19_xray\n"
     ]
    }
   ],
   "source": [
    "DATASET_LOCATION = pathlib.Path('covid19_xray')\n",
    "\n",
    "DATASET_LOCATION.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = \"https://www.kaggle.com/api/v1/datasets/download/khoongweihao/covid19-xray-dataset-train-test-sets\"\n",
    "zip_path = pathlib.Path('~/Downloads/chest-xray-pneumonia.zip').expanduser()\n",
    "\n",
    "zip_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "with open(zip_path, 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=128):\n",
    "        file.write(chunk)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(DATASET_LOCATION)\n",
    "\n",
    "print(f\"Dataset location: {DATASET_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'combined_pneumonia_models.pth'\n",
    "NEW_DATA_PATH = 'covid19_xray'\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model loaded and moved to mps\n"
     ]
    }
   ],
   "source": [
    "# The test matches the architecture used for the saved model \n",
    "def build_model(weights='IMAGENET1K_V1'):\n",
    "    model = models.resnet34(weights=weights)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)\n",
    "    return model\n",
    "\n",
    "resnet34 = build_model()\n",
    "\n",
    "PRETRAINED_MODEL_PATH = \"combined_pneumonia_models.pth\"\n",
    "device = device\n",
    "state_dict = torch.load(PRETRAINED_MODEL_PATH, map_location=device, weights_only=True)\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, pretrained_model, state_dict):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.pretrained_model = pretrained_model\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(*list(self.pretrained_model.children())[:-2])\n",
    "    \n",
    "        self.pretrained_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self.additional_layers = nn.Sequential(\n",
    "            nn.Conv2d(512, 8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.3),\n",
    "            nn.AdaptiveAvgPool2d((28, 28)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 28 * 28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.additional_layers(x)\n",
    "        return x\n",
    "\n",
    "model = CombinedModel(pretrained_model=resnet34, state_dict=state_dict).to(device)\n",
    "model.eval() \n",
    "print(f\"Final model loaded and moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 188 samples across 2 classes\n"
     ]
    }
   ],
   "source": [
    "# I used a simpler set of transforms, but still similar to the ones used in the training process the model is built on\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\"covid19_xray/xray_dataset_covid19\", transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Test dataset contains {len(test_dataset)} samples across {len(test_dataset.classes)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed\n"
     ]
    }
   ],
   "source": [
    "# Here we pass new data through the model to obtian predictions on the new dataset\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "      \n",
    "        outputs = model(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Inference completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.70\n",
      "Class: NORMAL\n",
      "Precision: 0.17\n",
      "Recall: 0.10\n",
      "F1-Score: 0.12\n",
      "Support: 40.0\n",
      "Class: COVID\n",
      "Precision: 0.78\n",
      "Recall: 0.86\n",
      "F1-Score: 0.82\n",
      "Support: 148.0\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"NORMAL\", \"COVID\"]\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(all_labels, all_predictions, target_names=class_names, zero_division=0, output_dict=True)\n",
    "\n",
    "for class_name in class_names:\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"Precision: {report[class_name]['precision']:.2f}\")\n",
    "    print(f\"Recall: {report[class_name]['recall']:.2f}\")\n",
    "    print(f\"F1-Score: {report[class_name]['f1-score']:.2f}\")\n",
    "    print(f\"Support: {report[class_name]['support']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
